{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf4608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d020d",
   "metadata": {},
   "source": [
    "Let's start by reading in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4741047",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df=pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4bb4d6",
   "metadata": {},
   "source": [
    "Now let's get into some exploration</br>\n",
    "Try some of these:</br>\n",
    "\n",
    "* get a single bar chart\n",
    "* my_df.groupby(**output**).count()[**some output var without nulls**].plot(kind='bar')\n",
    "\n",
    "* get a scatter plot\n",
    "* my_df.plot(x=**your independent variable**,y=**your dependent variable**,kind='scatter')\n",
    "\n",
    "* get a stacked bar chart\n",
    "* my_df.groupby(**first categorical**,**second categorical**).count().unstack()[**some output var without nulls**].plot(stacked=True)\n",
    "\n",
    "* get historgram\n",
    "* my_df[**your continuous variable**].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a0ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c401ab4",
   "metadata": {},
   "source": [
    "Now we need to do some encoding</br>\n",
    "There are two types we are going over:\n",
    "* One Hot Encoding\n",
    " * ohe=OneHotEncoding()\n",
    " * ohe_data=ohe.fit_transform(**your categorical data**)\n",
    "* Label Encoding\n",
    " * le=LabelEncoding()\n",
    " * le_data=le.fit_transform(**your ordinal categorical data**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fafedf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0861d62",
   "metadata": {},
   "source": [
    "We can try some oversampling</br>\n",
    "Now letsus look at some oversampling or undersampling\n",
    "* oversample = SMOTE()\n",
    "* X, y= oversample.fit_resample(df_smote_set.drop('Outcome',axis=1), df_smote_set['Outcome'])\n",
    "\n",
    "Now let's split the data</br>\n",
    "* X=data.drop('output',axis=1)\n",
    "* y=data['output']\n",
    "* X_model,X_val,y_model,y_val=train_test_split(X,y,test_size=0.2)\n",
    "* X_train,X_test,y_train,y_test=train_test_split(X_model,y_model,test_size=0.2)\n",
    "\n",
    "Now let's do some modeling</br>\n",
    " * Logistic Regression\n",
    "\n",
    "  * lg=LogisticRegression()\n",
    "  * lg_fit=lg.fit(X_train,y_train)\n",
    "  * lg_preds=lg_fit.predict(X_test)\n",
    "  * accuracy_score(y_test,lg_preds)\n",
    "\n",
    " * Decision Tree\n",
    "\n",
    "  * dt=DecisionTreeClassifier()\n",
    "  * dt_fit=dt.fit(X_train,y_train)\n",
    "  * dt_preds=dt_fit.predict(X_test)\n",
    "  * accuracy_score(y_test,dt_preds)\n",
    "\n",
    " * Support Vector Machines\n",
    "\n",
    "  * svm=SVC()\n",
    "  * svm_fit=svm.fit(X_train,y_train)\n",
    "  * svm_preds=svm_fit.predict(X_test)\n",
    "  * accuracy_score(y_test,svm_preds)\n",
    "\n",
    " * Random Forest\n",
    "\n",
    "  * rf=RandomForestClassifier()\n",
    "  * rf_fit=rf.fit(X_train,y_train)\n",
    "  * rf_preds=rf_fit.predict(X_test)\n",
    "  * accuracy_score(y_test,rf_preds)\n",
    "\n",
    " * Gradient Boosting\n",
    "\n",
    "  * xgb=XGBClassifier()\n",
    "  * xgb_fit=xgb.fit(X_train,y_train)\n",
    "  * xgb_preds=xgb_fit.predict(X_test)\n",
    "  * accuracy_score(y_test,xgb_preds)\n",
    "\n",
    "\n",
    "Now for some training evaluation.</br>\n",
    "\n",
    " * rf=RandomForestClassifier()\n",
    " * rf_fit=rf.fit(X_train,y_train)\n",
    " * rf_preds=rf_fit.predict(X_test)\n",
    " * accuracy_score(y_test,rf_preds)\n",
    "\n",
    "\n",
    " * rf_val_preds= rf_fit(X_val)\n",
    " * accuracy_score(y_val,rf_val_preds)\n",
    "\n",
    "\n",
    "Try some different validation methods</br>\n",
    " * f1_score(rf_val_preds,y_val)\n",
    " * confusion_matrix(rf_val_preds,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2279ec07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75769d7c",
   "metadata": {},
   "source": [
    "Let us execute some additional ML Tools that can squeeze some accuracy from our model, and prevent overfitting</br>\n",
    "* Grid Searching\n",
    " * parameters = {'n_estimators':[50, 100,200], 'eta':[0.1,0.3,0.5]}\n",
    " * xgb=XGBClassifier()\n",
    " * grid_search_xgb = GridSearchCV(xgb, parameters)\n",
    " * gs_xgb=grid_search_xgb.fit(X,y)\n",
    " * gs_xgb.cv_results_\n",
    "\n",
    "* Cross Validation\n",
    " * cross_val_score_xgb=cross_val_score(xgb,X,y)\n",
    " * print(cross_val_score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688e55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6fbd9c1",
   "metadata": {},
   "source": [
    "Now let's save the model.</br>\n",
    "* Saving the model\n",
    " * pickle the model\n",
    " * model_file=open('model_folder/random_forest_model.pkl','wb')\n",
    " * pkl.dump(rf_model,model_file)\n",
    " * model_file.close()\n",
    "\n",
    "* Loading the model\n",
    " * model_file=open('model_folder/random_forest_model.pkl','rb')\n",
    " * rf_model_import=pkl.load(model_file)\n",
    " * model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0068f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
